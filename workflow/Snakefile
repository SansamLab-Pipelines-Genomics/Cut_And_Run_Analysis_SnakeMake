configfile: "config/config.yml"


##################################################################
##                       import modules                         ##
##################################################################

import pandas as pd
import re
import common_functions as cf
import shutil
from datetime import datetime
now = datetime.now()
tmstmp = str(now.strftime("%y%m%d_%H%M"))

##################################################################
##                read and modify samples table                 ##
##################################################################

# this reads the CSV file and sets an index using the values in the sample column.
samples_table = pd.read_csv(config["samples_csv"]).set_index("sample", drop=False)
samples_table = samples_table.applymap(str)
samples_table_w_merged_suffix = cf.add_merge_suffix_to_merged_samples(samples_table)


##################################################################
##                           rules                              ##
##################################################################


# to run snakemake without explicitly requesting any output files on the command line, we must request output files in the first rule. Therefore we include this otherwise useless rule here
rule all:
    input:
        expand(
            f"results/sicer/{{sample}}-W{str(config['sicer_windowSize'])}-G{str(config['sicer_gapSize'])}-FDR{str(config['sicer_fdr'])}-island.bed",
            sample=cf.make_all_treatments_table(samples_table_w_merged_suffix)[
                "sample"
            ].to_list(),
        ) if config['sicer_run'] == True else ".placeholder",
        expand(
            f"results/macs2_normalPeaks/{{sample}}_{str(config['macs2_minimum_FDR_cutoff'])}_peaks.narrowPeak",
            sample=cf.make_all_treatments_table(samples_table_w_merged_suffix)[
                "sample"
            ].to_list(),
        ) if config['macs2_run'] == True else ".placeholder",
        expand(
            f"results/macs2_broadPeaks/{{sample}}_{str(config['macs2_broad_minimum_FDR_cutoff'])}_peaks.broadPeak",
            sample=cf.make_all_treatments_table(samples_table_w_merged_suffix)[
                "sample"
            ].to_list(),
        ) if config['macs2Broad_run'] == True else ".placeholder",
        expand(
            "results/merged/{sample}.bam",
            sample=set(samples_table["merged_sample"].to_list()),
        ),
        #"results/Report.html",
        "results/" + tmstmp + "_run_details_" + config["experimentName"] + "/config.yml",
        "results/" + tmstmp + "_run_details_" + config["experimentName"] + "/" + config["samples_csv"],
        "results/" + tmstmp + "_run_details_" + str(config["experimentName"]) + "/repo_release.txt",

##################################################################
##                       document run                           ##
##################################################################

# copy config and samples files to a directory
rule copy_config_files:
    output:
        "results/" + tmstmp + "_run_details_{sample}/config.yml",
        "results/" + tmstmp + "_run_details_{sample}/" + config["samples_csv"]
    params:
        config["samples_csv"]
    run:
        shutil.copyfile('config/config.yml', output[0])
        shutil.copyfile(params[0], output[1])


# write the current repo release to a file
rule write_repo_release:
    output:
        "results/" + tmstmp + "_run_details_{sample}/repo_release.txt"
    shell:
        """
        git describe --tag > {output}
        """        
        
        
rule trim_reads_with_trimmomatic:
    input:
        unpack(
            lambda wildcards: {
                "fq1": samples_table.loc[wildcards.sample, "fastq1"],
                "fq2": samples_table.loc[wildcards.sample, "fastq2"],
            }
        ),  # <--- we need to wrap our input function inside a special Snakemake function called unpack() which turns the dict into a collection of named inputs
    output:
        trimmed1=temp("results/trimmed/{sample}_trimmomatic_R1.fastq.gz"),
        trimmed2=temp("results/trimmed/{sample}_trimmomatic_R2.fastq.gz"),
        orphaned1=temp("results/trimmed/{sample}_trimmomatic_orphaned_R1.fastq.gz"),
        orphaned2=temp("results/trimmed/{sample}_trimmomatic_orphaned_R2.fastq.gz"),
    params:
        trimmomatic_threads=config["trimmomatic_threads"],
        trimmomatic_adapterfile=config["trimmomatic_adapterfile"],
    conda:
        "envs/trim_reads_with_trimmomatic.yml"
    envmodules:
        config["trimmomatic"]
    log:
        "results/logs/snakelogs/trim_reads_with_trimmomatic.{sample}.log",
    wildcard_constraints:
        sample="((?!_merged).)*",
    shell:
        """
        trimmomatic PE -threads {params.trimmomatic_threads} {input.fq1} {input.fq2} {output.trimmed1} {output.orphaned1} {output.trimmed2} {output.orphaned2} ILLUMINACLIP:{params.trimmomatic_adapterfile}:2:15:4:4:true LEADING:20 TRAILING:20 SLIDINGWINDOW:4:15 MINLEN:25
        """


rule trim_reads_with_cutadapt:
    input:
        R1="results/trimmed/{sample}_trimmomatic_R1.fastq.gz",
        R2="results/trimmed/{sample}_trimmomatic_R2.fastq.gz",
    output:
        trimmed1=temp("results/trimmed/{sample}_trimmed_R1.fastq.gz"),
        trimmed2=temp("results/trimmed/{sample}_trimmed_R2.fastq.gz"),
    params:
        cutadapt_adapterfile=config["cutadapt_adapterfile"],
    conda:
        "envs/trim_reads_with_cutadapt.yml"
    envmodules:
        config["cutadapt"]
    log:
        "results/logs/snakelogs/trim_reads_with_cutadapt.{sample}.log",
    wildcard_constraints:
        sample="((?!_merged).)*",
    shell:
        """
        cutadapt --json {log} --cores=0 -a file:{params.cutadapt_adapterfile} -A file:{params.cutadapt_adapterfile} -a G{{100}} -A G{{100}} --minimum-length 25 --quality-cutoff 20,20 -e 0.2 --output {output.trimmed1} --paired-output {output.trimmed2} {input.R1} {input.R2}
        """


rule align_reads_with_bowtie2:
    input:
        R1="results/trimmed/{sample}_trimmed_R1.fastq.gz",
        R2="results/trimmed/{sample}_trimmed_R2.fastq.gz",
    params:
        bowtie2_genome=config["bowtie2_genome"],
        bowtie2_threads=config["bowtie2_threads"],
        bowtie2_samtools_threads=config["bowtie2_samtools_threads"],
    output:
        bam="results/aligned/{sample}.bam",
        bai="results/aligned/{sample}.bam.bai",
    wildcard_constraints:
        sample="((?!_merged).)*",
    conda:
        "envs/align_reads_with_bowtie2.yml"
    envmodules:
        config["bowtie2"],
        config["samtools"],
    log:
        "results/logs/snakelogs/align_reads_with_bowtie2.{sample}.log",
    shell:
        """
        bowtie2 --met-file {log} --threads {params.bowtie2_threads} --dovetail --phred33 --maxins 2000 -x {params.bowtie2_genome} -1 {input.R1} -2 {input.R2} | samtools view -b - | samtools sort --threads {params.bowtie2_samtools_threads} - -o {output.bam}
        samtools index {output.bam}
        """
        
        
rule quality_filter_aligned_reads:
    input:
        bam="results/aligned/{sample}.bam",
    output:
        bam="results/aligned_and_filtered/{sample}.bam",
        bai="results/aligned_and_filtered/{sample}.bam.bai"
    params:
        bowtie2_samtools_threads=config["bowtie2_samtools_threads"],
        flag=config["samtools_filter_flag"],
    wildcard_constraints:
        sample="((?!_merged).)*",
    conda:
        "envs/samtools.yml"
    envmodules:
        config["samtools"]
    shell:
        """
        samtools view -h --threads {params.bowtie2_samtools_threads} -b -q 10 -F {params.flag} {input.bam} > {output.bam}
        samtools index {output.bam}
        """


def bamFilenames_from_mergedSamples(wildcard):
    df = samples_table.set_index("merged_sample")
    mylist = list(df.loc[wildcard, "sample"].astype(str))
    if len(mylist) == 1:
        return ' '.join("results/aligned_and_filtered/" + str(mylist[1]) + ".bam")
    else:
        return ' '.join(["results/aligned_and_filtered/" + str(s) + ".bam" for s in mylist])
    
rule merge_replicates:
    input:
        expand(
            "results/aligned_and_filtered/{sample}.bam",
            sample=samples_table["sample"].to_list()
        ),
        expand(
            "results/aligned_and_filtered/{sample}.bam.bai",
            sample=samples_table["sample"].to_list()
        ),
    params:
        bams=lambda wildcards: bamFilenames_from_mergedSamples(wildcards.sample),
        bowtie2_samtools_threads=config["bowtie2_samtools_threads"],
    output:
        bam="results/merged/{sample}.bam",
        bai="results/merged/{sample}.bam.bai",
    envmodules: 
        config["samtools"],
    shell:
        """
        samtools merge -@ {params.bowtie2_samtools_threads} {output.bam} {params.bams}
        samtools index -@ {params.bowtie2_samtools_threads} {output.bam}
        """
        
rule dummy:
    output:
        ".placeholder"
    shell:
        """
        touch {output}
        """
